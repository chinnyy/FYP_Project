laby_95$norm<- laby_95$sum/mean(laby_95$sum)
return(laby_95)
}
laby_order_95<- fun_rem_5(laby_order)
View(laby_order_95)
length(laby_order_95)
length(laby_95)-1
length(laby_order_95)-1
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$norm<- laby_95$sum/mean(laby_95$sum)
data.frame(laby_95[1:3], lapply(laby_95[4:length(laby_95)-1], function(x){
x/mean(laby_95$sum)
}))
return(laby_95)
}
laby_order_95<- fun_rem_5(laby_order)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$norm<- laby_95$sum/mean(laby_95$sum)
laby_norm<- data.frame(laby_95[1:3], lapply(laby_95[4:length(laby_95)-1], function(x){
x/mean(laby_95$sum)
}))
return(laby_norm)
}
laby_order_95<- fun_rem_5(laby_order)
View(laby_order)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$norm<- laby_95$sum/mean(laby_95$sum)
#  laby_norm<- data.frame(laby_95[1:3], lapply(laby_95[4:length(laby_95)-1], function(x){
x/mean(laby_95$sum)
}))
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$norm<- laby_95$sum/mean(laby_95$sum)
# laby_norm<- data.frame(laby_95[1:3], lapply(laby_95[4:length(laby_95)-1], function(x){
#   x/mean(laby_95$sum)
#
# }))
#
return(laby_norm)
}
laby_order_95<- fun_rem_5(laby_order)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$norm<- laby_95$sum/mean(laby_95$sum)
# laby_norm<- data.frame(laby_95[1:3], lapply(laby_95[4:length(laby_95)-1], function(x){
#   x/mean(laby_95$sum)
#
# }))
#
return(laby_95)
}
laby_order_95<- fun_rem_5(laby_order)
View(laby_order_95)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
laby_norm<- laby_95[,4:length(laby_95)-2]/laby_95$factor
return(laby_norm)
}
laby_order_95<- fun_rem_5(laby_order)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
laby_norm<- cbind(laby_95[1:3],laby_95[,4:length(laby_95)-2]/laby_95$factor)
return(laby_norm)
}
laby_order_95<- fun_rem_5(laby_order)
length(laby_95)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
# laby_norm<- cbind(laby_95[1:3],laby_95[,4:length(laby_95)-2]/laby_95$factor)
#
#
return(laby_95)
}
laby_order_95<- fun_rem_5(laby_order)
length(laby_order_95)-2
laby_order_95[,4:length(laby_order_95)-2]
laby_order_95[,6:length(laby_order_95)-2]
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
laby_norm<- cbind(laby_95[1:3],laby_95[,6:length(laby_95)-2]/laby_95$factor)
return(laby_norm)
}
laby_order_95<- fun_rem_5(laby_order)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
# laby_norm<- cbind(laby_95[1:3],laby_95[,6:length(laby_95)-2]/laby_95$factor)
#
return(laby_95)
}
laby_order_95_2<- fun_rem_5(laby_order)
View(laby_order_95)
View(laby_order_95_2)
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
laby_norm<- cbind(laby_95[1:3],laby_95[,6:length(laby_95)-2]/laby_95$factor)
return(laby_norm)
}
laby_order_norm<- fun_rem_5(laby_order)
View(laby_order_norm)
# Plot abundance map of laby only
png(file=paste0(wd,"/PLOTS/Q1/Laby_abundance_map_logged.jpeg"),width=1536,height=802)
dev.off()
# Preparing laby vs protist data: abundance with other class (Kingdom level)
laby_euk<- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
View(laby_euk)
# Normalize data
laby_euk_norm<- fun_rem_5(laby_euk)
View(laby_euk_norm)
# Preparing laby vs protist data: abundance with other class (Supergroup level)
laby_stram<- asv_sample_wide %>%
filter(supergroup == "Stramenopiles")%>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize data
laby_stram_norm<- fun_rem_5(laby_stram)
# Preparing laby vs protist data: abundance with other class (Division level)
laby_sagen<- asv_sample_wide %>%
filter(division == "Sagenista")%>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize data
laby_sagen_norm<- fun_rem_5(laby_sagen)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_euk_norm,cols=colnames(laby_euk_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_stram_norm,cols=colnames(laby_stram_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
base_world+
geom_scatterpie(aes(x=longitude, y=latitude, r=log(norm)*2),
data=laby_sagen_norm,cols=colnames(laby_sagen_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_sagen_norm,cols=colnames(laby_sagen_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
laby_all_euk_label_wide <- asv_sample_wide %>%
group_by(label,date,depth_level,depth,substrate,latitude,longitude,climate,temperature,salinity,ice_coverage,region,ecosystem,substrate_type,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(label,date,depth_level,depth,substrate,latitude,longitude,climate,temperature,salinity,ice_coverage,region,ecosystem,substrate_type,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
as.data.frame()
View(laby_all_euk_label_wide)
laby_all_euk_fc_wide <- asv_sample_wide %>%
group_by(file_code,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(file_code,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
as.data.frame()
View(laby_all_euk_fc_wide)
laby_all_euk_fc_wide <- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(file_code,latitude,longitudeclass)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
as.data.frame()
laby_all_euk_fc_wide <- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
as.data.frame()
# Normalize values
laby_all_euk_fc_norm <- fun_rem_5(laby_all_euk_fc_wide)
laby_all_euk_fc_wide <- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize values
laby_all_euk_fc_norm <- fun_rem_5(laby_all_euk_fc_wide)
View(laby_all_euk_fc_norm)
# Loop to obtain r values
cor_res_df <- data.frame() # Create empty list
all_class_name<- data.frame(name= unique(asv_sample_wide$class))%>%
filter(!name == "Labyrinthulomycetes")
for (i in all_class_name[,1]){
cor_res <- cor.test(log(laby_all_euk_fc_norm$Labyrinthulomycetes), log(laby_all_euk_fc_norm[,i]), method = "spearman",exact=FALSE,formula = ~ x + y,alternative = "two.sided")
cor_res_col<- cbind(class = i, r = round(cor_res$estimate[["rho"]],2),p_value = cor_res$p.value)
cor_res_df <- rbind(cor_res_df,cor_res_col)
}
View(cor_res_df)
# Select top 10 R values
cor_res_df <-cor_res_df%>%
arrange(desc(r))%>%
slice(1:10)
View(cor_res_df)
# Plotting statistics from a paired correlation
m2_cor_plot_laby_vs_10_euk = list()
for (i in cor_res_df[,1]) {
plot = ggplot( mapping = aes(x = log(laby_all_euk_fc_norm$Labyrinthulomycetes), y = log(laby_all_euk_fc_norm[,i]))) +
geom_point( color = '#440154', size = 1) +
sm_statCorr(corr_method = 'spearman',
fit.params = list(linetype = 'dashed'),
borders = FALSE,
lm_method = lm)+
ggtitle(paste("Correlation plot of ",i))+
labs(y= i, x = "Labyrinthulomycetes")+
theme(plot.title = element_text(hjust = 0.5))
m2_cor_plot_laby_vs_10_euk[[i]] <- ggplot_gtable(ggplot_build(plot))
}
do.call("grid.arrange", c(m2_cor_plot_laby_vs_10_euk, ncol=3))## display plot
log(laby_all_euk_fc_norm[,i]
)
laby_all_euk_fc_norm[,i]
laby_all_euk_fc_norm$i
laby_all_euk_fc_norm$Pirsonia_Clade
### Preparing laby data: abundance within class
laby_order_wide <- laby_asv_wide %>%
group_by(file_code,latitude,longitude,date,depth_level,substrate,climate,temperature,salinity,ice_coverage,ecosystem,order,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each file_code
select( -n_reads) %>% group_by(file_code,latitude,longitude,date,depth_level,substrate,climate,temperature,salinity,ice_coverage,ecosystem,order)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same order
spread(key = order, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., 12:17)))%>% # Add another row that counts the abundance of all
as.data.frame()
View(laby_order_wide)
### Preparing laby data: abundance within class
laby_order_wide <- laby_asv_wide %>%
group_by(file_code,latitude,longitude,order,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each file_code
select( -n_reads) %>% group_by(file_code,latitude,longitude,order)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same order
spread(key = order, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
View(laby_order_norm)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_order_norm,cols=colnames(laby_order_norm[,c(4:9)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_viridis_d()
# Create base map
worldmap <- map_data ("world")# From the tidyverse package
base_world  <- ggplot()+
coord_fixed() +
xlab("") + ylab("") +
geom_polygon(data=worldmap, aes(x=long, y=lat, group=group),
colour="dark green", fill="light green")+
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_rect(fill = 'light blue', colour = 'light blue'),
axis.line = element_line(colour = "white"), #legend.position="none",
axis.ticks=element_blank(), axis.text.x=element_blank(),
axis.text.y=element_blank())
## Load dataset
wd<- setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory
asv_sample_wide<-read.table(file = paste0(wd,'/DATA/ALL/metapr2_ASVs_selected_abundance_Eukaryota.tsv'), sep = '\t', header = TRUE)
# Filter for class laby
laby_asv_wide <- filter(asv_sample_wide,class == "Labyrinthulomycetes")
# Preparing laby data: Relative abundance within class
laby_order <- laby_asv_wide %>%
group_by(file_code,latitude,longitude,order,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,order)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = order, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Function to remove bottom 5% of the dataset and normalize all columns
fun_rem_5<- function(data) {
p05 <- quantile(data$sum, 0.05)
laby_95<- data[which(data$sum >= p05),]
# Normalize all columns
laby_95$factor<- laby_95$sum/mean(laby_95$sum)
laby_norm<- cbind(laby_95[1:3],laby_95[,6:length(laby_95)-2]/laby_95$factor)
return(laby_norm)
}
laby_order_norm<- fun_rem_5(laby_order)
### Plotting scatterpie map of orders in class Laby
png(file=paste0(wd,"/PLOTS/Q1/Laby_global_abun_scatterpie_map.jpeg"),width=1536,height=802)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_order_norm,cols=colnames(laby_order_norm[,c(4:9)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_viridis_d()
dev.off()
# Preparing laby vs protist data: abundance with other class (Kingdom level)
laby_euk<- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize data
laby_euk_norm<- fun_rem_5(laby_euk)
# Preparing laby vs protist data: abundance with other class (Supergroup level)
laby_stram<- asv_sample_wide %>%
filter(supergroup == "Stramenopiles")%>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize data
laby_stram_norm<- fun_rem_5(laby_stram)
# Preparing laby vs protist data: abundance with other class (Division level)
laby_sagen<- asv_sample_wide %>%
filter(division == "Sagenista")%>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each location
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
mutate(class = replace(class, class != "Labyrinthulomycetes", "Not Labyrinthulomycetes"))%>%
group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same location
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize data
laby_sagen_norm<- fun_rem_5(laby_sagen)
# Plotting scatterpie map of laby vs protist data: abundance with other class (Kingdom level)
png(file=paste0(wd,"/PLOTS/Q1/Laby_vs_eukaryotes_scatterpie_map.jpeg"),width=1536,height=802)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_euk_norm,cols=colnames(laby_euk_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
dev.off()
# Plotting scatterpie map of laby vs protist data: abundance with other class (Supergroup level)
png(file=paste0(wd,"/PLOTS/Q1/Laby_vs_stramenopiles_scatterpie_map.jpeg"),width=1536,height=802)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_stram_norm,cols=colnames(laby_stram_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
dev.off()
# Plotting scatterpie map of laby vs protist data: abundance with other class (Division level)
png(file=paste0(wd,"/PLOTS/Q1/Laby_vs_sagenista_scatterpie_map.jpeg"),width=1536,height=802)
base_world+
geom_scatterpie(aes(x=longitude, y=latitude),
data=laby_sagen_norm,cols=colnames(laby_sagen_norm[,c(4:5)]), color=NA)+
theme(legend.position = "bottom")+
scale_fill_manual(values = c("#440154","#21918c"))
dev.off()
# Part 2: Co-occurrence plots of Laby vs other protist classes
# METHOD 2: Find the correlation between classes within the kingdom of eukaryotes and laby and find the top 10 R scores
# Preparing data: count total count of each class under each sampling occurrence
laby_all_euk_fc_wide <- asv_sample_wide %>%
group_by(file_code,latitude,longitude,class,n_reads) %>%
dplyr::summarise(total_count=n()*n_reads,.groups = 'drop')%>% # Find the total count for each label
select( -n_reads) %>% group_by(file_code,latitude,longitude,class)%>%
dplyr::summarise(total_count = sum(total_count),.groups = 'drop')%>%# Merging values of the same class
spread(key = class, value = total_count)%>% # Convert to wide data
replace(is.na(.), 0) %>%
mutate(sum = rowSums(select(., -c(1,2,3))))%>% # Add another row that counts the abundance of all
as.data.frame()
# Normalize values
laby_all_euk_fc_norm <- fun_rem_5(laby_all_euk_fc_wide)
# Loop to obtain r values
cor_res_df <- data.frame() # Create empty list
all_class_name<- data.frame(name= unique(asv_sample_wide$class))%>%
filter(!name == "Labyrinthulomycetes")
for (i in all_class_name[,1]){
cor_res <- cor.test(log(laby_all_euk_fc_norm$Labyrinthulomycetes), log(laby_all_euk_fc_norm[,i]), method = "spearman",exact=FALSE,formula = ~ x + y,alternative = "two.sided")
cor_res_col<- cbind(class = i, r = round(cor_res$estimate[["rho"]],2),p_value = cor_res$p.value)
cor_res_df <- rbind(cor_res_df,cor_res_col)
}
# Select top 10 R values
cor_res_df <-cor_res_df%>%
arrange(desc(r))%>%
slice(1:10)
# Plotting statistics from a paired correlation
m2_cor_plot_laby_vs_10_euk = list()
for (i in cor_res_df[,1]) {
plot = ggplot( mapping = aes(x = log(laby_all_euk_fc_norm$Labyrinthulomycetes), y = log(laby_all_euk_fc_norm[,i]))) +
geom_point( color = '#440154', size = 1) +
sm_statCorr(corr_method = 'spearman',
fit.params = list(linetype = 'dashed'),
borders = FALSE,
lm_method = lm)+
ggtitle(paste("Correlation plot of ",i))+
labs(y= i, x = "Labyrinthulomycetes")+
theme(plot.title = element_text(hjust = 0.5))
m2_cor_plot_laby_vs_10_euk[[i]] <- ggplot_gtable(ggplot_build(plot))
}
do.call("grid.arrange", c(m2_cor_plot_laby_vs_10_euk, ncol=3))## display plot
# Save plots to .jpeg. Makes a separate file for each plot.
for (i in 1:10) {
png(file=paste0(wd,"/PLOTS/Q1/Method_2_Laby_vs_",cor_res_df[i,1],"_corr_plot.jpeg"),width=1536,height=802)
gridExtra::grid.arrange(m2_cor_plot_laby_vs_10_euk[[i]])
dev.off()
}
## Load dataset
wd<- setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory
## Load dataset
wd<- setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory
library(plyr) # data wrangling
library(dplyr) # data wrangling
library(tidyverse) # data wrangling and management
## Load dataset
wd<- setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory
asv_sample_wide<-read.table(file = paste0(wd,'/DATA/ALL/metapr2_ASVs_selected_abundance_Eukaryota.tsv'), sep = '\t', header = TRUE)
View(asv_sample_wide)
colnames(asv_sample_wide)
summary(asv_sample_wide)
asv_sample_wide <- as.data.frame(unclass(asv_sample_wide),                     # Convert all columns to factor
stringsAsFactors = TRUE)
summary(asv_sample_wide)
# Filter for class laby
laby_asv_wide <- filter(asv_sample_wide,class == "Labyrinthulomycetes")
View(laby_asv_wide)
summary(laby_asv_wide)
asv_sample_wide[1,]
library(data.table)
woa23_temp <- fread(paste0(wd,'/DATA/woa23_decav91C0_t00mn01.csv'))
## Load dataset
wd<- setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory
